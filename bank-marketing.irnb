{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"Analysis of bank marketing dataset on R, v1"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"#=============================================\n# Bank Marketing\n#=============================================\n\n# Load dataset from working directory\ndf <- read.csv(\"bank.csv\", sep = ';')\n\n# Exploratory analysis\ndim(df)\nstr(df)\nsummary(df)\ndf <- df[order(df$y),] # ordering by 'y'\nlevels(df$y) <- c(0,1) # no-0, yes-1\n\n# Missing values\nsum(is.na(df)) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d7bdd14f1ad9e83416e8fa07272313d28b5ebaa","collapsed":true},"cell_type":"code","source":"# Numeric and factor split \ndfn <- df[,sapply(df, function(x) is.numeric(x))]\nstr(dfn)\nsummary(dfn)\ndfc <- df[,sapply(df, is.factor)]\nstr(dfc)\nsummary(dfc)\n\n# visualisation\nfor (i in (1:ncol(dfc))){\n  plot(dfc[,i], col = rainbow(20), main = names(dfc)[i])\n}\n\nfor (i in (1:ncol(dfn))){\n  hist(dfn[,i], col = rainbow(20), main = names(dfn)[i])\n  boxplot(dfn[,i], col = rainbow(20), main = names(dfn)[i])\n}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4f6743a4cc9d815d56f9c1ede7ccc05537306e5","collapsed":true},"cell_type":"code","source":"# Data normalisation: Scaling the numeric variables using max-min method\ndf$pdays[df$pdays==-1] <- 0\nfor (i in c(1:ncol(df))){\n  if (sapply(df[i], is.numeric))\n  df[i] <- (max(df[i])-df[i])/max(df[i])\n}\n\ndfn <- df[,sapply(df, is.numeric)]\nstr(dfn)\nsummary(dfn)\ndfn <- cbind(dfn, df$y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1029d596d2834176e0489597b19af309e9cf39e9","collapsed":true},"cell_type":"code","source":"# Feature construction: F-score to calculate interaction effects\nfs <- matrix(0,ncol(dfn)-1,ncol(dfn)-1) # Empty square matrix\nv <- 0\nfor (i in 1:ncol(fs)){\n  for (j in 1:i){\n    v <-0\n    v <- dfn[,i]*dfn[,j] # product of 2 columns\n    meanpos <- mean(v[c(0:4000)])\n    meanneg <- mean(v[c(4001:4521)])\n    meantot <- mean(v[c(0:4521)])\n    varpos <- var(v[c(0:4000)])\n    varneg <- var(v[c(4001:4521)])\n    fs[i,j] <- (((meanpos-meantot)^2) + ((meanneg-meantot)^2))/(varpos+varneg) # F-score\n  }\n}\n\n# selection of important features after examining the F-scores\na <- cbind.data.frame(df$duration*df$previous, df$duration^2 , df$duration*df$balance, \n                      df$duration*df$campaign, df$duration*df$pdays)\nnames(a) <- c('dur_prev','dur2','dur_bal','dur_camp','dur_pdays')\ndf1 <- cbind.data.frame(df, a)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b284bb6ca4ac62270a06adbdc493aa1eaddbd98","collapsed":true},"cell_type":"code","source":"# Feature Selection using Random Forest \nlibrary(randomForest)\nrffit <- randomForest(data = df1, df1$y~., ntree = 500, mtry = 12, importance = T)\nimportance(rffit)\nvarImpPlot(rffit) # The attribute and gini plot give the relative importance of the \n                    # features towards the model.\n\n# Feature Selection: Boruta\nlibrary(Boruta)\nbattrib <- Boruta(data = df, df$y~.)\nbattrib # Important, tentative and rejected features shown\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbd20625833086a07d2030eebc6f201786389b79","collapsed":true},"cell_type":"code","source":"# Class Balancing\nplot(df$y, col = rainbow(20), main = \"Success rate\") # There is an imbalance.\nnon <- df1[df1$y==0,] # non-responders, y=0\nres <- df1[df1$y==1,] # responders, y=1\nindexnon <- sample(1:nrow(non), 2*nrow(res), replace = F) # non-responders taken twice \n                                                            # as much as responders\ntrain <- rbind(res, non[indexnon,])\nstr(train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"669936039587a8bd20b2818b775636cbf2300ea4","collapsed":true},"cell_type":"code","source":"# Splitting our dataset into test and train\ntrain <- train[,-c(9,11,14,15,16,18,22)] # Test dataset doesn't accomodate these features. \n                                            # Can be observed after EDA.\ns <- sample(nrow(train), 0.6*nrow(train), replace = F)\nstrain <- train[s,]\nstest <- train[-s,]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ad3d4c70a81f069d98f761af1e1ef25dc065623","collapsed":true},"cell_type":"code","source":"# SVM model 1, radial kernel, on 60% train\nlibrary(e1071)\nwts <- 100/table(strain$y) # Consider weights\nsvmfit1 <- tune(svm, data = strain, y~., class.weights = wts, probability = T, # Tuning model for best fit\n                ranges = list(gamma = 2^(-8:0), cost = 10^(-2:4)), scale = F)\n\nradfit1 <- svmfit1$best.model # Best fit(gamma and cost) model used\nsummary(radfit1)                \npred <- predict(radfit1, newdata = stest[,-12]) # Prediction on split test\ntable(predict = pred, truth = stest$y) # Cross-tab \nsum(pred==stest$y)/length(stest$y) # Accuracy\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4cc4670113264ab9339474fb3b3b10b00bf0ab7","collapsed":true},"cell_type":"code","source":"#===================================================================\n# Test\n#===================================================================\n\n# Loading test data set, EDA and all the previous analysis performed\n# Load dataset from working directory\ndftest <- read.csv(\"test.csv\")\n\n# Exploratory analysis\ndim(dftest)\nstr(dftest)\nsummary(dftest)\n\n# Missing values\nsum(is.na(dftest)) \n\n# Numeric and factor split \ndftestn <- dftest[,sapply(dftest, function(x) is.numeric(x))]\nstr(dftestn)\nsummary(dftestn)\ndftestc <- dftest[,sapply(dftest, is.factor)]\nstr(dftestc)\nsummary(dftestc)\n\n# visualisation\nfor (i in (1:ncol(dftestc))){\n  plot(dftestc[,i], col = rainbow(20), main = names(dftestc)[i])\n}\n\nfor (i in (1:ncol(dftestn))){\n  hist(dftestn[,i], col = rainbow(20), main = names(dftestn)[i])\n  boxplot(dftestn[,i], col = rainbow(20), main = names(dftestn)[i])\n}\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eeed637ab19d0aafa0ce9d2fd14db67b8ead5165","collapsed":true},"cell_type":"code","source":"# Data normalisation: Scaling the numeric variables using max-min method\ndftest$pdays[dftest$pdays==-1] <- 0\nfor (i in c(1:ncol(dftest))){\n  if (sapply(dftest[i], is.numeric))\n    dftest[i] <- (max(dftest[i])-dftest[i])/max(dftest[i])\n}\n\na2 <- cbind.data.frame(dftest$duration*dftest$previous, dftest$duration^2 , dftest$duration*dftest$balance, \n                       dftest$duration*dftest$campaign, dftest$duration*dftest$pdays)\nnames(a2) <- c('dur_prev','dur2','dur_bal','dur_camp','dur_pdays')\ndftest <- cbind.data.frame(dftest, a2)\ndftest <- (subset(dftest, select = -Id))\ndftest <- dftest[,-c(16,11,9,15,14,21,17)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d56c914c2c0aad26cf30904d6d8526479370af57","collapsed":true},"cell_type":"code","source":"#====================================================================================\n# SVM Model2: radial kernel, trained on complete train, applied on given test dataset\n#====================================================================================\n\nwts <- 100/table(df$y) # Consider weights\nsvmfit2 <- tune(svm, data = df, y~., class.weights = wts, probability = T, # Tuning model for best fit\n                ranges = list(gamma = 2^(-8:0), cost = 10^(-2:4)), scale = F)\n\nradfit2 <- svmfit2$best.model # Best fit(gamma and cost) model used\nsummary(radfit2)                \npred_test <- predict(radfit2, newdata = dftest) # Prediction on given test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0619bcf73598bb2eeb36de995b9607cb2d89337a","collapsed":true},"cell_type":"code","source":"# Submission as a csv file\npred_test <- as.data.frame(pred_test)\nwrite.csv(pred_test,\"tested01.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"daa8103777df491e04f98169f2661f2367abe910"},"cell_type":"markdown","source":"The model gives an estimated accuracy of 87% on the test dataset. \nIt has to be mentioned that the test dataset provoded is highly biased, and an unbiased set could enable better prediction.\nMany other models can be tested, and I shall try to implement them soon."}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}